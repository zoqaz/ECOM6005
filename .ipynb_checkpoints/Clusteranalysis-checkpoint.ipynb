{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "### Zohaib Qazi\n",
    "### 19712200\n",
    "### zohaib@curtin.edu.au\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import chardet\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def all_pairs(lst):\n",
    "    if len(lst) < 2:\n",
    "        yield []\n",
    "        return\n",
    "    if len(lst) % 2 == 1:\n",
    "        # Handle odd length list\n",
    "        for i in range(len(lst)):\n",
    "            for result in all_pairs(lst[:i] + lst[i+1:]):\n",
    "                yield result\n",
    "    else:\n",
    "        a = lst[0]\n",
    "        for i in range(1,len(lst)):\n",
    "            pair = (a,lst[i])\n",
    "            for rest in all_pairs(lst[1:i]+lst[i+1:]):\n",
    "                yield [pair] + rest\n",
    "\n",
    "def grouping(articles): #Function creates sets out of clusters and appends them into a list <clustersets>\n",
    "    outputlist = []\n",
    "    for i in articles:\n",
    "        grouped = i.groupby('Cluster')\n",
    "        clusters_month = []\n",
    "        for name, group in grouped:\n",
    "            i = group['Word']\n",
    "            cluster_set = set(i)\n",
    "            clusters_month.append(cluster_set) #clusters holds 30 sets. 30 clusters of words from one month. \n",
    "        outputlist.append(clusters_month)\n",
    "    return outputlist\n",
    "\n",
    "def intersections(clusters): #creates lists of intersects between clusters\n",
    "    commons = []\n",
    "    for i in range(0,len(clusters)):\n",
    "        current = clusters[i]\n",
    "        for j in current:\n",
    "            for ii in range(i+1,len(clusters)):\n",
    "                compare = clusters[ii]\n",
    "                for jj in compare:\n",
    "                    select = j.intersection(jj)\n",
    "                    if select != set():\n",
    "                        commons.append(list(j.intersection(jj)))\n",
    "                    else:\n",
    "                        pass\n",
    "    return commons\n",
    "                \n",
    "def sort_intersects(intersect):\n",
    "    singles = []\n",
    "    doubles = []\n",
    "    triples = []\n",
    "    quads = []\n",
    "    pentas = []\n",
    "    extra = []\n",
    "    \n",
    "    for i in intersect:\n",
    "        if len(i) == 1:\n",
    "            singles.append(i)\n",
    "        elif len(i) == 2:\n",
    "            doubles.append(i)\n",
    "        elif len(i) == 3:\n",
    "            triples.append(i)\n",
    "        elif len(i) == 4:\n",
    "            quads.append(i)\n",
    "        elif len(i) == 5:\n",
    "            pentas.append(i)\n",
    "        else:\n",
    "            extra.append(i)\n",
    "            \n",
    "    doubles_iter = [[tuple(i) for i in doubles]]\n",
    "    triples_iter = [[tuple(i) for i in triples]]\n",
    "    quads_iter = [[tuple(i) for i in quads]]\n",
    "    pentas_iter = [[tuple(i) for i in pentas]]\n",
    "    extras_iter = [[tuple(i) for i in extra]]\n",
    "    \n",
    "    freq_singles = Counter(chain.from_iterable(singles)).most_common()\n",
    "    freq_doubles = Counter(chain.from_iterable(doubles_iter)).most_common()    \n",
    "    freq_triples = Counter(chain.from_iterable(triples_iter)).most_common()\n",
    "    freq_quads = Counter(chain.from_iterable(quads_iter)).most_common()\n",
    "    freq_pentas = Counter(chain.from_iterable(pentas_iter)).most_common()\n",
    "    freq_extras = Counter(chain.from_iterable(extras_iter)).most_common()\n",
    "    \n",
    "    freqs = [freq_singles, freq_doubles, freq_triples, freq_quads, freq_pentas, freq_extras]\n",
    "    return freqs\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters/RIO\\RIO_Month_0_Clusters.csv\n",
      "Clusters/RIO\\RIO_Month_10_Clusters.csv\n",
      "Clusters/RIO\\RIO_Month_11_Clusters.csv\n",
      "Clusters/RIO\\RIO_Month_12_Clusters.csv\n",
      "Clusters/RIO\\RIO_Month_13_Clusters.csv\n",
      "Clusters/RIO\\RIO_Month_14_Clusters.csv\n",
      "Clusters/RIO\\RIO_Month_1_Clusters.csv\n",
      "Clusters/RIO\\RIO_Month_2_Clusters.csv\n",
      "Clusters/RIO\\RIO_Month_3_Clusters.csv\n",
      "Clusters/RIO\\RIO_Month_4_Clusters.csv\n",
      "Clusters/RIO\\RIO_Month_5_Clusters.csv\n",
      "Clusters/RIO\\RIO_Month_6_Clusters.csv\n",
      "Clusters/RIO\\RIO_Month_7_Clusters.csv\n",
      "Clusters/RIO\\RIO_Month_8_Clusters.csv\n",
      "Clusters/RIO\\RIO_Month_9_Clusters.csv\n",
      "8\n",
      "7\n",
      "0\n",
      "282\n",
      "108\n",
      "93\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "paths = glob.glob('Clusters/RIO/*.csv')\n",
    "\n",
    "clustersplit = pd.DataFrame(columns = ['Ticker', 'n_negative', 'n_neutral', 'n_positive'])\n",
    "\n",
    "positive_arts = []\n",
    "negative_arts = []\n",
    "neutral_arts = []\n",
    "\n",
    "for i in paths:\n",
    "    print(i)\n",
    "    data = pd.read_csv(i, encoding = 'ISO-8859-1')\n",
    "\n",
    "    sentiment = list(data.columns[4:])\n",
    "    if sentiment == ['POSITIVE']:\n",
    "        positive_arts.append(data)\n",
    "    elif sentiment == ['NEGATIVE']:\n",
    "        negative_arts.append(data)\n",
    "    elif sentiment == ['NEUTRAL']:\n",
    "        neutral_arts.append(data)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(len(negative_arts))\n",
    "print(len(positive_arts))\n",
    "print(len(neutral_arts))\n",
    "    \n",
    "    \n",
    "cluster_positive = grouping(positive_arts)\n",
    "cluster_negative = grouping(negative_arts)\n",
    "cluster_neutral = grouping(neutral_arts)\n",
    "\n",
    "pos_intersects = intersections(cluster_positive)\n",
    "neg_intersects = intersections(cluster_negative)\n",
    "neut_intersects = intersections(cluster_neutral)\n",
    "\n",
    "positive_commons = sort_intersects(pos_intersects)\n",
    "negative_commons = sort_intersects(neg_intersects)\n",
    "neutral_commons = sort_intersects(neut_intersects)\n",
    "\n",
    "ticker = paths[0][9:12]\n",
    "neg = len(negative_arts)\n",
    "pos = len(positive_arts)\n",
    "neut = len(neutral_arts)\n",
    "clustersplit = clustersplit.append({'Ticker' : ticker , 'n_negative' : neg, 'n_neutral' : neut, 'n_positive' : pos} , ignore_index=True)\n",
    "\n",
    "\n",
    "count = 0\n",
    "for i in negative_commons[1:2]:\n",
    "    for ii in i:\n",
    "        count += 1\n",
    "        \n",
    "for i in positive_commons[1:2]:\n",
    "    for ii in i:\n",
    "        count +=1        \n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "for i in negative_commons[2:3]:\n",
    "    for ii in i:\n",
    "        count += 1\n",
    "        \n",
    "for i in positive_commons[3:3]:\n",
    "    for ii in i:\n",
    "        count +=1        \n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "for i in negative_commons[3:4]:\n",
    "    for ii in i:\n",
    "        count += 1\n",
    "        \n",
    "for i in positive_commons[3:4]:\n",
    "    for ii in i:\n",
    "        count +=1        \n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "for i in negative_commons[4:5]:\n",
    "    for ii in i:\n",
    "        count += 1\n",
    "        \n",
    "for i in positive_commons[4:5]:\n",
    "    for ii in i:\n",
    "        count +=1        \n",
    "print(count)\n",
    "\n",
    "\n",
    "df_total = clustersplit[\"n_negative\"] + clustersplit[\"n_neutral\"] + clustersplit[\"n_positive\"] \n",
    "# export commons for each stock\n",
    "#append to a bigger frequency table which checks ALL stocks frequencies for positive/negative\n",
    "#need to make small positive and big positive/negatives (in original script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_total = clustersplit[\"n_negative\"] + clustersplit[\"n_neutral\"] + clustersplit[\"n_positive\"] \n",
    "df_rel = clustersplit[clustersplit.columns[1:]].div(df_total, 0)*100\n",
    "\n",
    "df_total2 = pd.concat([df_total2, df_total], ignore_index=True)\n",
    "\n",
    "#clustersplit = pd.concat([clustersplit, clustersplit2], ignore_index=True)\n",
    "\n",
    "clustersplit[0:2].plot(\n",
    "    x = 'Ticker', \n",
    "    kind = 'barh', \n",
    "    stacked = True, \n",
    "    title = 'Sentiment Segmentation Per Ticker', \n",
    "    mark_right = True)\n",
    "\n",
    "# for n in df_rel: \n",
    "#     for i, (cs, ab, pc) in enumerate(zip(clustersplit.iloc[:, 1:].cumsum(1)[n],  \n",
    "#                                          clustersplit[n], df_rel[n])): \n",
    "#         plt.text(cs - ab / 2, i, str(np.round(pc, 1)) + '%',  \n",
    "#                  va = 'center', ha = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
